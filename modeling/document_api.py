#document_api.py
import requests
import xml.etree.ElementTree as ET
import pymysql
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter

from config import API_KEY, BASE_URL, DB_CONFIG


def get_text(item, tag):
    el = item.find(tag)
    if el is None or el.text is None:
        return ""
    return el.text.strip()

def safe(v):
    return v if v is not None else ""


def build_session():
    session = requests.Session()
    retry = Retry(
        total=5,
        connect=5,
        read=3,
        backoff_factor=0.7,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET"],
        raise_on_status=False,
    )
    session.mount("https://", HTTPAdapter(max_retries=retry))
    session.headers.update({"User-Agent": "bizinfo-ingest/1.0"})
    return session


def lcategory_is_tech(lcat):
    if not lcat:
        return False
    parts = [p.strip() for p in lcat.replace("|", "@").split("@")]
    return "ê¸°ìˆ " in parts


def fetch_page(session, api_key, page_index=1, page_unit=100):
    params = {
        "crtfcKey": api_key,
        "dataType": "rss",
        "pageIndex": page_index,
        "pageUnit": page_unit,
        "searchCnt": page_unit,
    }

    r = session.get(BASE_URL, params=params, timeout=(5, 30))
    r.raise_for_status()

    root = ET.fromstring(r.text)
    channel = root.find("channel")
    if channel is None:
        raise ValueError("RSS channel ì—†ìŒ")

    raw_items = channel.findall("item")
    raw_count = len(raw_items)

    tot_cnt = None
    rows = []

    for it in raw_items:
        seq = get_text(it, "seq")
        if not seq:
            continue

        lcat = get_text(it, "lcategory")
        if not lcategory_is_tech(lcat):
            continue

        if tot_cnt is None:
            tc = get_text(it, "totCnt")
            if tc and tc.isdigit():
                tot_cnt = int(tc)

        rows.append({
            "seq": seq,
            "title": get_text(it, "title"),
            "link": get_text(it, "link"),
            "author": get_text(it, "author"),
            "exc_instt_nm": get_text(it, "excInsttNm"),
            "description": get_text(it, "description"),
            "pub_date": get_text(it, "pubDate"),
            "reqst_dt": get_text(it, "reqstDt"),
            "trget_nm": get_text(it, "trgetNm"),
            "print_flpth_nm": get_text(it, "printFlpthNm"),
            "print_file_nm": get_text(it, "printFileNm"),
            "flpth_nm": get_text(it, "flpthNm"),
            "file_nm": get_text(it, "fileNm"),
            "hash_tags": get_text(it, "hashtags"),
        })

    return raw_count, tot_cnt, rows


def parse_hashtags(hash_tags_str):
    """
    í•´ì‹œíƒœê·¸ ë¬¸ìì—´ íŒŒì‹±
    ì˜ˆ: "AI,ë¹…ë°ì´í„°,í´ë¼ìš°ë“œ" â†’ ["AI", "ë¹…ë°ì´í„°", "í´ë¼ìš°ë“œ"]
    """
    if not hash_tags_str:
        return []
    
    # ì‰¼í‘œë¡œ splití•˜ê³  ë¹ˆ ë¬¸ìì—´ ì œê±°
    tags = [tag.strip() for tag in hash_tags_str.split(",") if tag.strip()]
    return tags


def parse_files(print_file_nm_str, print_flpth_nm_str):
    """
    íŒŒì¼ëª…, íŒŒì¼ê²½ë¡œ ë¬¸ìì—´ íŒŒì‹±
    ì˜ˆ: "íŒŒì¼1.hwp@íŒŒì¼2.pdf" + "ê²½ë¡œ1@ê²½ë¡œ2" 
        â†’ [("íŒŒì¼1.hwp", "ê²½ë¡œ1"), ("íŒŒì¼2.pdf", "ê²½ë¡œ2")]
    """
    if not print_file_nm_str or not print_flpth_nm_str:
        return []
    
    # @ êµ¬ë¶„ìë¡œ split
    file_names = [f.strip() for f in print_file_nm_str.split("@") if f.strip()]
    file_paths = [p.strip() for p in print_flpth_nm_str.split("@") if p.strip()]
    
    if len(file_names) != len(file_paths):
        print(f"âš ï¸ íŒŒì¼ëª…({len(file_names)})ê³¼ ê²½ë¡œ({len(file_paths)}) ê°œìˆ˜ ë¶ˆì¼ì¹˜")
        return []
    
    return list(zip(file_names, file_paths))


def ingest_to_db(api_key, page_unit=100, max_pages=None):
    session = build_session()
    conn = pymysql.connect(**DB_CONFIG)

    try:
        with conn.cursor() as cursor:
            page = 1
            tot_cnt_seen = None
            inserted = 0
            seen_seq = set()

            while True:
                raw_count, tot_cnt, rows = fetch_page(
                    session,
                    api_key=api_key,
                    page_index=page,
                    page_unit=page_unit,
                )

                if tot_cnt_seen is None and tot_cnt is not None:
                    tot_cnt_seen = tot_cnt

                print(
                    f"page={page} raw_items={raw_count} "
                    f"tech_items={len(rows)} totCnt={tot_cnt_seen}"
                )

                if raw_count == 0:
                    break

                for notice in rows:
                    seq = notice["seq"]
                    if seq in seen_seq:
                        continue
                    seen_seq.add(seq)

                    cursor.execute(
                        "SELECT 1 FROM project_notices WHERE seq = %s",
                        (seq,),
                    )
                    if cursor.fetchone():
                        continue

                    # âœ… 1. project_notices í…Œì´ë¸”ì— ê¸°ë³¸ ì •ë³´ë§Œ INSERT
                    sql = """
                        INSERT INTO project_notices (
                            seq, title, link, author, exc_instt_nm,
                            description, pub_date, reqst_dt, trget_nm
                        )
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """

                    cursor.execute(
                        sql,
                        (
                            safe(seq),
                            safe(notice.get("title")),
                            safe(notice.get("link")),
                            safe(notice.get("author")),
                            safe(notice.get("exc_instt_nm")),
                            safe(notice.get("description")),
                            safe(notice.get("pub_date")),
                            safe(notice.get("reqst_dt")),
                            safe(notice.get("trget_nm")),
                        ),
                    )

                    notice_id = cursor.lastrowid

                    # âœ… 2. notice_files í…Œì´ë¸”ì— íŒŒì¼ ì •ë³´ INSERT
                    print_file_nm_str = safe(notice.get("print_file_nm"))
                    print_flpth_nm_str = safe(notice.get("print_flpth_nm"))
                    file_nm_str = safe(notice.get("file_nm"))
                    flpth_nm_str = safe(notice.get("flpth_nm"))

                    # ğŸ”¥ ë””ë²„ê¹… ë¡œê·¸
                    print(f"\n{'='*60}")
                    print(f"ğŸ” ê³µê³  seq={seq} íŒŒì¼ ì •ë³´")
                    print(f"{'='*60}")
                    print(f"ğŸ“Œ ì œëª©: {notice.get('title')[:50]}...")
                    print(f"ğŸ“„ ë³¸ë¬¸íŒŒì¼ëª…: [{print_file_nm_str}]")
                    print(f"ğŸ“‚ ë³¸ë¬¸ê²½ë¡œ: [{print_flpth_nm_str}]")
                    print(f"ğŸ“ ì²¨ë¶€íŒŒì¼ëª…: [{file_nm_str}]")
                    print(f"ğŸ“‚ ì²¨ë¶€ê²½ë¡œ: [{flpth_nm_str}]")

                    print_files = parse_files(print_file_nm_str, print_flpth_nm_str)
                    attach_files = parse_files(file_nm_str, flpth_nm_str)
                    all_files = print_files + attach_files

                    print(f"âœ… ë³¸ë¬¸íŒŒì¼: {len(print_files)}ê°œ")
                    print(f"âœ… ì²¨ë¶€íŒŒì¼: {len(attach_files)}ê°œ")
                    print(f"âœ… ì´ íŒŒì¼: {len(all_files)}ê°œ")
                    
                    if all_files:
                        for i, (fname, fpath) in enumerate(all_files, 1):
                            print(f"   íŒŒì¼ {i}: {fname}")
                    else:
                        print(f"   âš ï¸ íŒŒì¼ ì—†ìŒ")
                    
                    for file_name, file_path in all_files:
                        sql_file = """
                            INSERT INTO notice_files (
                                notice_id, print_file_nm, print_flpth_nm
                            )
                            VALUES (%s, %s, %s)
                        """
                        cursor.execute(sql_file, (notice_id, file_name, file_path))

                    # âœ… 3. notice_hashtags í…Œì´ë¸”ì— í•´ì‹œíƒœê·¸ INSERT
                    hash_tags_str = safe(notice.get("hash_tags"))
                    
                    # ğŸ”¥ í•´ì‹œíƒœê·¸ ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
                    print(f"ğŸ·ï¸  ì›ë³¸ í•´ì‹œíƒœê·¸: [{hash_tags_str}]")
                    
                    hashtags = parse_hashtags(hash_tags_str)
                    
                    print(f"âœ… íŒŒì‹±ëœ í•´ì‹œíƒœê·¸: {len(hashtags)}ê°œ")
                    if hashtags:
                        for i, tag in enumerate(hashtags, 1):
                            print(f"   íƒœê·¸ {i}: {tag}")
                    else:
                        print(f"   âš ï¸ í•´ì‹œíƒœê·¸ ì—†ìŒ")
                    print(f"{'='*60}\n")

                    for tag in hashtags:
                        if tag:
                            sql_hashtag = """
                                INSERT INTO notice_hashtags (
                                    notice_id, tag_name
                                )
                                VALUES (%s, %s)
                            """
                            cursor.execute(sql_hashtag, (notice_id, tag))

                    inserted += 1

                conn.commit()

                if max_pages is not None and page >= max_pages:
                    break
                if tot_cnt_seen is not None and page * page_unit >= tot_cnt_seen:
                    break

                page += 1

            print(f"\nDBì— ìƒˆë¡œ ì ì¬ëœ ê¸°ìˆ  ê³µê³ : {inserted}ê±´")
            return inserted

    finally:
        conn.close()



if __name__ == "__main__":
    ingest_to_db(API_KEY, page_unit=100)